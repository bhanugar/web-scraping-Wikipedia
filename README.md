Web Scraping Wikipedia 
======================================

Project Overview
----------------

This project involves web scraping Wikipedia to gather information on over 1,000 movies and organizing it into a structured DataFrame. The goal is to eventually build a recommendation system that predicts box office collections using machine learning techniques.

Current Status
--------------

*   **Web Scraping**: Successfully scraped movie data from Wikipedia, including key attributes such as:
    
    *   Movie Title
        
    *   Director
        
    *   Distributor
        
    *   Running Time
        
    *   Language
        
    *   Cast
        
    *   Budget
        
    *   Release Date
        
    *   Country
        
    *   Box Office
        
    *   Plot
        
*   **DataFrame Creation**: Organized the scraped data into a DataFrame for further processing and analysis.
    

Future Work
-----------

*   Implement machine learning models to predict box office collections.
    
*   Build a recommendation engine based on various movie attributes.
    

Technologies Used
-----------------

*   **Python**: Web scraping, data collection, and preprocessing.
    
*   **Libraries**:
    
    *   BeautifulSoup: For parsing HTML and extracting data.
        
    *   pandas: For data manipulation and DataFrame creation.
        
    *   requests: For making HTTP requests to Wikipedia.
        

Future Machine Learning Implementation
--------------------------------------

The machine learning models for predicting box office collections will be developed in the next phase.

Acknowledgements
----------------

This project is inspired by the need for data-driven insights into movie collections. Thanks to Wikipedia for providing the open-source data used in this analysis.
